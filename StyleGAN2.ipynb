{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d61717",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RubeRad/StyleGAN2-TensorFlow-2.x/blob/master/StyleGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99623dc8",
   "metadata": {
    "id": "99623dc8"
   },
   "source": [
    "# Intro\n",
    "StyleGAN2 is an AI for generating photorealistic synthetic faces. It was trained on huge numbers of photos of faces from the internet. \"GAN\" means \"Generative Adversarial Network\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e8b29",
   "metadata": {
    "id": "e61e8b29"
   },
   "source": [
    "**Network** because it's a neural network like we've seen with the MNIST example: data fed into an initial layer of nodes, which feeds through arcs and weights and many more layers of nodes to an output layer.\n",
    "\n",
    "**Generative** because it is a **Generator** of images. Basically you feed a list of random numbers into the input layer, and the output layer is pixels of an image (kind of backwards from MNIST, where pixels are fed into the input, and the output layer is numbers).\n",
    "\n",
    "**Adversarial** is the interesting part. They actually started with a **Discriminator** network, which was designed (more like MNIST) to accept pixels in the input layer, and have an output layer with just two nodes: Real or Fake. Then the baby, untrained Discriminator, and baby, untrained Generator were put in an MMA Cage to train each other: \n",
    "* The Generator would try to generate images that would be realistic enough to fool the Discriminator\n",
    "* ...which trained the Discriminator to be more discriminating in order to defeat the Generator.\n",
    "* ...which trained the Generator to make more realistic images that were better able to fool the Discriminator.\n",
    "* ...which trained the Discriminator to be more discriminating.\n",
    "* ...which trained the Generator to make more realistic images.\n",
    "* ...you get the picture.\n",
    "\n",
    "Eventually the Generator and the Discriminator reach a balanced detente where neither is improving anymore (the Adversarial training has converged to its optimum). Now that the Generator is in amazing shape, the Discriminator doesn't have much use (or maybe I'm just not creative enough to imagine its uses), and is left behind as a worn-out sparring partner, while the Generator goes and gets famous on the internet.\n",
    "\n",
    "Go check out the generator's work at [thispersondoesnotexist.com](http://thispersondoesnotexist.com)\n",
    "\n",
    "The original StyleGAN2 was a research project from the GPU-manufacturer NVIDIA, using tensorflow v1:\n",
    "\n",
    "* Paper: https://arxiv.org/pdf/1812.04948.pdf\n",
    "* Video: https://youtu.be/kSLJriaOumA\n",
    "* Code: https://github.com/NVlabs/stylegan\n",
    "* FFHQ: https://github.com/NVlabs/ffhq-dataset\n",
    "\n",
    "I used to have a StyleGAN2 notebook based on [this tutorial by Mikael Christensen](https://colab.research.google.com/drive/1ShgW6wohEFQtqs_znMna3dzrcVoABKIH). Unfortunately, Google Colab advanced to tensorflow v2, and I couldn't get that notebook to work anymore. The capability in this network is thanks to the work of Alberto Rosas Garcia, who upgraded StyleGAN2 to work with tensorflow v2, and [posted his version onto github](https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3d8f4",
   "metadata": {
    "id": "cdb3d8f4"
   },
   "source": [
    "# Setup\n",
    "This is a group of cells to get all the code and data in place, because it's not just standard stuff like numpy and pands that can be brought in with `import`. We also need a large data file with all the weights.\n",
    "\n",
    "This group of cells will need to be run once at the beginning of each session. Then this section can be collapsed in Colab, so it's out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6574f7",
   "metadata": {
    "id": "6b6574f7"
   },
   "outputs": [],
   "source": [
    "# import the normal stuff\n",
    "import os\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55b8ae",
   "metadata": {
    "id": "3d55b8ae"
   },
   "outputs": [],
   "source": [
    "# DO THIS IF YOU ARE IN COLAB\n",
    "# Clone the repository with the TensorFlow2 update to StyleGAN2\n",
    "# Thanks Alberto Rosas!!\n",
    "%cd /content\n",
    "!git clone https://github.com/ruberad/StyleGAN2-TensorFlow-2.x.git stylegan2\n",
    "%cd /content/stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfb443",
   "metadata": {
    "id": "78dfb443"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # common neural network module\n",
    "# import StyleGAN2-specific stuff from \n",
    "# that python we just pulled down from github\n",
    "from utils.utils_stylegan2 import convert_images_to_uint8\n",
    "from stylegan2_generator   import StyleGan2Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351e418",
   "metadata": {
    "id": "3351e418"
   },
   "outputs": [],
   "source": [
    "# Check if you have access to a GPU in this (virtual) machine\n",
    "!nvidia-smi -L\n",
    "gpuname = tf.test.gpu_device_name()\n",
    "print('GPU Identified at: \"{}\"'.format(gpuname))\n",
    "\n",
    "# set the impl and gpu variables appropriately\n",
    "# these are needed so the Generator knows how to run\n",
    "if gpuname:\n",
    "  impl = 'cuda'\n",
    "  gpu = True\n",
    "  print('yay fast!')\n",
    "else:\n",
    "  impl = 'ref'\n",
    "  gpu = False\n",
    "  print('aww, slow.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0a34f",
   "metadata": {
    "id": "a9d0a34f"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "# This is the public URL of the online file with weights that StyleGan2 needs for generating faces\n",
    "url = 'https://drive.google.com/uc?export=download&confirm=pbef&id=1afMN3e_6UuTTPDL63WHaA0Fb9EQrZceE'\n",
    "# This is where we want the file to go (path on the virtual machine)\n",
    "out = 'weights/ffhq.npy'\n",
    "\n",
    "if os.path.exists(out):\n",
    "  print('ffhq.npy weights file is present')\n",
    "else:\n",
    "  gdown.download(url, out, quiet=False)\n",
    "\n",
    "# After this cell is run, there should be a file ffhq.npy in the weights/ subdirectory,\n",
    "# check the colab folder sidebar to make sure it's there.\n",
    "# The full file is about 250MB \n",
    "# That's alotta weights! This is a BIG neural network!\n",
    "# The paper says the network has 26.2 million trainable parameters\n",
    "\n",
    "# FFHQ stands for Flickr Faces, High Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f26387",
   "metadata": {
    "id": "c4f26387"
   },
   "outputs": [],
   "source": [
    "# Now that we have all the weights, we can create the Generator object\n",
    "# that can use those weights. We'll call it sg2\n",
    "sg2 = StyleGan2Generator(weights='ffhq', impl=impl, gpu=gpu)\n",
    "\n",
    "# If this says \"Loaded ffhq generator weights!\", we're ready to start generating faces!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f9d6d",
   "metadata": {
    "id": "4c7f9d6d"
   },
   "source": [
    "# First run\n",
    "These commands will seem mysterious at first, but we wil understand them more as we go along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372256e4",
   "metadata": {
    "id": "372256e4"
   },
   "source": [
    "Random Number Generators (rngs) are technically only *Pseudo*random. They are in fact quite deterministic. If you give them the same seed, they will repeatably generate the same stream of 'random' numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ukh6hkGlFj4K",
   "metadata": {
    "id": "ukh6hkGlFj4K"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161394ac",
   "metadata": {
    "id": "161394ac"
   },
   "source": [
    "Let's use the RNG to generate a pile of random numbers. Each one is from the Standard Normal distribution (mean $\\mu=0$, standard deviation $\\sigma=1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fda32a",
   "metadata": {
    "id": "58fda32a"
   },
   "outputs": [],
   "source": [
    "z = rng.randn(1, 512).astype('float32')\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee1e23",
   "metadata": {
    "id": "c4ee1e23"
   },
   "source": [
    "That's a lot of numbers, mostly in the $\\pm 1$ range, some a little bigger. We can slap the values into a histogram and see the typical 'bell curve' of a Normal distribution. (And if you go back and rerun just the `z=rng` cell, you will see it sampled new numbers, further down the rng stream (But if you go further back and rerun the `seed=1` cell, you will see that it samples the exact same 'random' numbers every time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74ad23",
   "metadata": {
    "id": "fc74ad23"
   },
   "outputs": [],
   "source": [
    "fig=plt.figure( figsize=(8,3) )\n",
    "ax=plt.gca()\n",
    "ax.hist(list(z), bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575fee3",
   "metadata": {
    "id": "4575fee3"
   },
   "source": [
    "Now we use our generator object to push our pile of seeded random numbers through the 'Mapping Network' to get something that for now we'll just call `w`. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07759836",
   "metadata": {
    "id": "07759836"
   },
   "outputs": [],
   "source": [
    "w = sg2.mapping_network(z)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff45f0",
   "metadata": {
    "id": "05ff45f0"
   },
   "source": [
    "That `w` is numbers in the right ranges, and in the right 'shape', to feed into the input layer of the Generator. So let's push it on through!\n",
    "\n",
    "This may take a bunch of seconds. Even for a computer it takes a while to propagate 18x512 input numbers through a network of 26.2 million weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5aad4",
   "metadata": {
    "id": "f9b5aad4"
   },
   "outputs": [],
   "source": [
    "out = sg2.synthesis_network(w)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6rm4bWGHAZAV",
   "metadata": {
    "id": "6rm4bWGHAZAV"
   },
   "source": [
    "What is that `out` that we got out? It's a pile of 1024x1024 numbers, which need to be reinterpreted as pixels of an image. Fortunately all this stylegan2 python includes a function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86363ef",
   "metadata": {
    "id": "b86363ef"
   },
   "outputs": [],
   "source": [
    "img = convert_images_to_uint8(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C22bFhCZAmRx",
   "metadata": {
    "id": "C22bFhCZAmRx"
   },
   "source": [
    "And now that we have an image, this is how we use matplotlib to display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e454b",
   "metadata": {
    "id": "5d6e454b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12,12) )  # like normal\n",
    "ax  = plt.gca()                         \n",
    "ax.axis('off')     # turn off the axis lines, we're not plotting a graph\n",
    "ax.imshow(img)     # bet you can guess what 'imshow' does\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129856d4",
   "metadata": {
    "id": "129856d4"
   },
   "source": [
    "OK, there's a dude, he looks like a grumpy late-middle-aged white guy. (Note I can 'predict' what face you will see even before you run this notebook, because we have taken control of the seeding of the RNG, and the same grumpy white guy will get generated from `seed=1` every time.)\n",
    "\n",
    "I'm pretty sure this grumpy guy's name is ***Gus***.\n",
    "\n",
    "Believe it or not, even though this looks like a real photo taken of a real guy, there is no Gus. This image is completely synthetic. Take a moment to bask in how amazing that is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485c14c",
   "metadata": {
    "id": "3485c14c"
   },
   "source": [
    "## Exercise\n",
    "Use the code cell below to copy all the important python commands from above (leaving out the ones that show intermediate stuff we don't want to look at every time), and run it a bunch of times with different seeds to see a bunch of different faces! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9876d4",
   "metadata": {
    "id": "fc9876d4"
   },
   "source": [
    "Use this markup cell to accumulate a list of seeds that yield faces that interest you\n",
    "* put a seed here\n",
    "* and here\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2a7a7",
   "metadata": {
    "id": "0af2a7a7"
   },
   "outputs": [],
   "source": [
    "# Use this code cell to gather all the important python commands from above\n",
    "# So an image can be generated and displayed by running just this one code cell\n",
    "seed=2 # or seed = np.random.randint(1000000)\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aed802",
   "metadata": {
    "id": "49aed802"
   },
   "source": [
    "# Mean Girl\n",
    "Who is 'Mean Girl'? And why is she so mean? Let's get a look at her...\n",
    "\n",
    "The Generator object has an attribute (a data element which is part of the object) called `dlatent_avg`. This is a collection of numbers in the right ranges, and of the right `shape` to input to the input layer of the Generator network. This is called a `latent space vector`, and the shorthand is typically to call it `w` or a vector in $w$-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9c908",
   "metadata": {
    "id": "95f9c908"
   },
   "outputs": [],
   "source": [
    "w_avg = sg2.dlatent_avg\n",
    "w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb37ce",
   "metadata": {
    "id": "abeb37ce"
   },
   "source": [
    "Let's feed `w_avg` into the Generator and see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec2e28",
   "metadata": {
    "id": "eeec2e28"
   },
   "outputs": [],
   "source": [
    "out = sg2.synthesis_network(w_avg)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0be1e",
   "metadata": {
    "id": "75f0be1e"
   },
   "source": [
    "As before, we need to take this pile of 1024x1024 numbers, reinterpreted them as pixels of an image, and display it with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbf652",
   "metadata": {
    "id": "acbbf652"
   },
   "outputs": [],
   "source": [
    "img = convert_images_to_uint8(out) # same as before\n",
    "fig = plt.figure( figsize=(12,12) )\n",
    "ax  = plt.gca() \n",
    "ax.axis('off')\n",
    "ax.imshow(img) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089f829",
   "metadata": {
    "id": "3089f829"
   },
   "source": [
    "She doesn't look so mean after all! \n",
    "\n",
    "But she is *average* (aka *mean*, get it?). This is the image that is generated from the input vector which is called `dlatent_avg`, which is an input vector in the `middle` of the (highly multidimensional) $w$-space of input vectors, and a face which is in some sense in the `middle` of all the images in the training set. From the paper:\n",
    "\n",
    "> In case of FFHQ this point represents a sort of an average face ... the \"mean\" face of FFHQ. This face is similar for all trained networks.\n",
    "\n",
    "[Open up the paper](https://arxiv.org/pdf/1812.04948.pdf) and look closely at Page 8, Figure 8, the face at $\\psi=0$. It is very similar to this face, maybe the same woman on a different day, with a different haircut, and a different(?) gray shirt. That figure in the paper was likely generated with an earlier training of StyleGAN2, but \"similar for all trained networks\" means each time the tweaked their network design and retrained, the \"mean girl\" ended up looking pretty much the same.\n",
    "\n",
    "What does it mean that this \"mean girl\" is a woman? A white woman?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014fcbc",
   "metadata": {
    "id": "9014fcbc"
   },
   "source": [
    "# Deviations from the mean\n",
    "Note that `w_avg=sg2.dlatent_avg` and `w=sg2.mapping_network(z)` are both, when you boil it down, piles of numbers, of the same shape, the right shape to feed into the input layer of the Generator. They are **vectors**, and because they are vectors, they can be manipulated as vectors, i.e. added, subtracted, scaled, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c864d",
   "metadata": {
    "id": "ba9c864d"
   },
   "outputs": [],
   "source": [
    "# in case we don't have Mean Girl's w_avg defined from above\n",
    "w_avg = sg2.dlatent_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59ae0f",
   "metadata": {
    "id": "6e59ae0f"
   },
   "outputs": [],
   "source": [
    "# Let's go back to Gus\n",
    "seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029f240",
   "metadata": {
    "id": "1029f240"
   },
   "outputs": [],
   "source": [
    "# Generate a z from the seed and map a w from the z\n",
    "rng = np.random.RandomState(seed)\n",
    "z = rng.randn(1, 512).astype('float32')\n",
    "w = sg2.mapping_network(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a7b08",
   "metadata": {
    "id": "a16a7b08"
   },
   "outputs": [],
   "source": [
    "# This is the vector between Mean Girl and Gus\n",
    "# (or whatever face comes from your chosen seed)\n",
    "dw = w - w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d4771",
   "metadata": {
    "id": "b86d4771"
   },
   "source": [
    "Simple algebra tells us that since `dw = w - w_avg`, to get from Mean Girl to Gus we just need to `w = w_avg + dw`. Which is also to say `dw` is the *direction* from Mean Girl to Gus. But remember what we learned from *Despicable Me*: vectors have not only direction, but also ***magnitude***.\n",
    "\n",
    "<img src=\"https://i.kym-cdn.com/photos/images/original/001/755/239/9da.jpg\" width=\"400\">\n",
    "\n",
    "To get from Mean Girl's `w_avg` to Gus' `w` means going the full magnitude of `dw` away from `w_avg`\n",
    "> `w = w_avg + 1.0*dw`\n",
    "\n",
    "But what if we don't want to go the whole distance? What if we only want to go halfway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7ccef",
   "metadata": {
    "id": "0fb7ccef"
   },
   "outputs": [],
   "source": [
    "# This is the 'truncation factor' t\n",
    "t = 0.5\n",
    "w_trunc = w_avg + t*dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a7f83",
   "metadata": {
    "id": "983a7f83"
   },
   "outputs": [],
   "source": [
    "# now do the stuff from before to show what face we get\n",
    "out = sg2.synthesis_network(w_trunc)\n",
    "img = convert_images_to_uint8(out)\n",
    "fig = plt.figure( figsize=(12,12) )\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "img_plot = ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb8092",
   "metadata": {
    "id": "e7bb8092"
   },
   "source": [
    "Hey wow, Gus isn't so grumpy. Or old. Does this face seem 'halfway between' Mean Girl and original Gus?\n",
    "\n",
    "Play around with different truncation factors `t`. What happens when you slide `t` from 1.0 down to 0.0? What happens if you keep going and let `t` go ***negative***?!?!\n",
    "\n",
    "From the paper, the pair of faces generated by `w_avg + t*dw` and `w_avg - t*dw` are called \"anti-faces\"\n",
    "> By applying negative scaling to styles, we get the corresponding opposite or \"anti-face\". It is interesting that various high-level attributes often flip between the opposites, including viewpoint, glasses, age, coloring, hair length, and often gender.\n",
    "\n",
    "So the direction vector `dw` is called a ***style***. Mean Girl is the bland center of all faces (she has no style!), but applying randomly generated `dw` moves in the direction of applying styles such as the list in the quote. And moving in the opposite direction `-dw` applies the opposites of those styles. (This is why it's called ***Style***GAN2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31be76",
   "metadata": {
    "id": "bd31be76"
   },
   "source": [
    "## Exercise\n",
    "Refer to the list of interesting face seeds from the previous exercise. Go back through the cells above to re-generate some of those faces, and then modify `t` down through 0 and to negative to see how your face transforms to its anti-face. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4ba3b",
   "metadata": {
    "id": "49a4ba3b"
   },
   "source": [
    "## Exercise\n",
    "It's time to stop copy&pasting piles of the same commands over and over again. In programming, copying & pasting is always a sure sign that code needs to be modularized into functions for convenient reuse.\n",
    "\n",
    "In the code cells below, write the functions as described by the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abeecd",
   "metadata": {
    "id": "c5abeecd"
   },
   "outputs": [],
   "source": [
    "# given a seed s, return the z-vector of standard normal random numbers\n",
    "def sample_z(s):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975b662",
   "metadata": {
    "id": "f975b662"
   },
   "outputs": [],
   "source": [
    "# Test the sample_z() function, make sure it behaves as expected\n",
    "z=sample_z(1)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gkJOj31j9qvx",
   "metadata": {
    "id": "gkJOj31j9qvx"
   },
   "source": [
    "Don't move on to defining the next function until `sample_z()` is done and working. If you go through and implement all the functions and don't test until you get to the end, it is ***much*** harder to find the bugs, because they could be anywhere (will be everywhere)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f8d30",
   "metadata": {
    "id": "f83f8d30"
   },
   "outputs": [],
   "source": [
    "# given a z-vector, push it through generator g's mapping network to get a w-vector\n",
    "def map_z_to_w(g, z):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0dd5b",
   "metadata": {
    "id": "79b0dd5b"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "w = map_z_to_w(sg2, z) # note we pass sg2 in as generator g\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa707ceb",
   "metadata": {
    "id": "fa707ceb"
   },
   "outputs": [],
   "source": [
    "# Input a given w-vector to generator g and return the generated image\n",
    "def generate_image_from_w(g, w):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682af1b3",
   "metadata": {
    "id": "682af1b3"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "img = generate_image_from_w(sg2, w)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5_jghO5A-MvP",
   "metadata": {
    "id": "5_jghO5A-MvP"
   },
   "source": [
    "This next function should use all of the functions defined above. Make sure those little, simple ones are all working before starting on this big, complex one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c48ef",
   "metadata": {
    "id": "1b8c48ef"
   },
   "outputs": [],
   "source": [
    "# Starting from a seed s, compute the corresponding z and w\n",
    "# Then compute the style direction dw from generator g's mean girl\n",
    "# Then compute two different truncated w vectors, one that is +t away\n",
    "# from the mean, and one that is -t away from the mean\n",
    "# Use g to generate 3 images: the face, mean girl, and the anti-face\n",
    "# Use matplotlib to plot all three\n",
    "# (Refer to MatplotlibIntro.ipynb for a row of subplots 131 132 133)\n",
    "def plot_face_mean_anti(g, s, t=1.0):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce45d3",
   "metadata": {
    "id": "f3ce45d3"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "plot_face_mean_anti(sg2, 1) # try different seeds, different values for the +/-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a84524",
   "metadata": {
    "id": "28a84524"
   },
   "outputs": [],
   "source": [
    "# Similar to plot_face_mean_anti, but this time we want a 3x3 grid\n",
    "# Start by finding the z, w, and dw.\n",
    "# Also start a matplotlib figure going.\n",
    "# Use tvec=np.arange(start, limit, step) (with the right inputs) to\n",
    "# get 9 values equally spaced from t to -t (with 0 in the middle)\n",
    "# Matplotlib should have a 3x3 grid of subplots 331, 332, ... 339\n",
    "# Loop through tvec, and for each t:\n",
    "#   compute w_trunc = avg_w + t*dw\n",
    "#   generate the image for w_trunc\n",
    "#   create the next subplot\n",
    "#   show the image on it\n",
    "def plot_anti_face_grid(g, s, t=1.0):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92956a79",
   "metadata": {
    "id": "92956a79"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
